inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 4
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
finalactivation: [None, None, 'sigmoid']
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE 
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.966923076923077
Balanced acc: 0.9775
Average specificity: 0.965
Average sensitivity (Detection rate): 0.99
Average loss: [3.66464848]
Average False Alarm: 0.009999999999999998
Average F1: 0.8215767634854771
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|23.160000000000004|0.019999999999999997
|Predicted 1|0.8399999999999999|1.98

|Acc|Spec|Loss|
0.966923076923077|0.965|[3.66464848]
CV took 80.4844342244004 seconds
Pure training took 76.1960830705999
Test result on unseen data:
Average accuracy: 0.7772999999999999
Balanced acc: 0.7773
Average specificity: 0.9472
Average sensitivity (Detection rate): 0.6073999999999999
Average loss: nan
Average False Alarm: 0.3926
Average F1: 0.7317190699915673
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|94.72|39.26
|Predicted 1|5.28|60.739999999999995

|Acc|Spec|Loss|
0.7772999999999999|0.9472|nan
