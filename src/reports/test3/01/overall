inputsize: [[4, 4], [8, 8]]
inlayersize: [64, 32, 16]
latentsize: 2
outlayersize: ListWrapper([16, 32, 64])
outputsize: [[4, 4], [1, 1]]
finalactivation: [None, None, 'sigmoid']
Model has 2 inputs, class 0 is where the second input is drawn from a normal distribution with mean of the first input, class 1 is where it isnt. Double training data                 
losses: ['mean_absolute_error', 'mean_absolute_error', 'weighted_ce']
loss_weights: [1, 1, 1]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9715384615384616
Balanced acc: 0.9433333333333334
Average specificity: 0.9766666666666667
Average sensitivity (Detection rate): 0.9099999999999999
Average loss: [1.51223342]
Average False Alarm: 0.08999999999999998
Average F1: 0.8310502283105022
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|23.440000000000005|0.18
|Predicted 1|0.5599999999999999|1.8200000000000003

|Acc|Spec|Loss|
0.9715384615384616|0.9766666666666667|[1.51223342]
CV took 71.16861771459916 seconds
Pure training took 66.87196125560023
Test result on unseen data:
Average accuracy: 0.7258
Balanced acc: 0.7258
Average specificity: 0.9628
Average sensitivity (Detection rate): 0.48879999999999996
Average loss: nan
Average False Alarm: 0.5112000000000001
Average F1: 0.6406290956749672
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|96.28|51.120000000000005
|Predicted 1|3.7199999999999998|48.879999999999995

|Acc|Spec|Loss|
0.7258|0.9628|nan
