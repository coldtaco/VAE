inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 4
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
fc_size: [64, 32, 1]
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9784615384615385
Balanced acc: 0.8783333333333334
Average specificity: 0.9966666666666667
Average sensitivity (Detection rate): 0.76
Average loss: [3.45949533]
Average False Alarm: 0.24000000000000002
Average F1: 0.8444444444444444
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|11.959999999999999|0.24
|Predicted 1|0.04|0.7599999999999999

|Acc|Spec|Loss|
0.9784615384615385|0.9966666666666667|[3.45949533]
CV took 53.80219053299807 seconds
Pure training took 49.57096844259504
Test result on unseen data:
Average accuracy: 0.6498
Balanced acc: 0.6497999999999999
Average specificity: 0.9643999999999999
Average sensitivity (Detection rate): 0.3352
Average loss: nan
Average False Alarm: 0.6648
Average F1: 0.48905748468047855
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|96.43999999999998|66.47999999999999
|Predicted 1|3.5599999999999996|33.519999999999996

|Acc|Spec|Loss|
0.6498|0.9643999999999999|nan
