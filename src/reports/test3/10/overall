inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 1
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
finalactivation: [None, None, 'sigmoid']
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE 
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9823076923076923
Balanced acc: 0.9720833333333334
Average specificity: 0.9841666666666667
Average sensitivity (Detection rate): 0.96
Average loss: [6.98488968]
Average False Alarm: 0.039999999999999994
Average F1: 0.8930232558139535
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|23.62|0.07999999999999999
|Predicted 1|0.38|1.92

|Acc|Spec|Loss|
0.9823076923076923|0.9841666666666667|[6.98488968]
CV took 77.68442791819997 seconds
Pure training took 73.44048083880007
Test result on unseen data:
Average accuracy: 0.7534000000000001
Balanced acc: 0.7534
Average specificity: 0.9682
Average sensitivity (Detection rate): 0.5386
Average loss: nan
Average False Alarm: 0.46140000000000003
Average F1: 0.6859398879266428
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|96.82|46.14
|Predicted 1|3.18|53.86

|Acc|Spec|Loss|
0.7534000000000001|0.9682|nan
