inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 16
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
fc_size: [64, 32, 1]
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9753846153846154
Balanced acc: 0.8766666666666667
Average specificity: 0.9933333333333333
Average sensitivity (Detection rate): 0.76
Average loss: [3.28985469]
Average False Alarm: 0.24000000000000005
Average F1: 0.8260869565217391
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|11.919999999999998|0.24000000000000005
|Predicted 1|0.08|0.76

|Acc|Spec|Loss|
0.9753846153846154|0.9933333333333333|[3.28985469]
CV took 51.3861481489992 seconds
Pure training took 47.19646393079893
Test result on unseen data:
Average accuracy: 0.6533
Balanced acc: 0.6533
Average specificity: 0.9642000000000001
Average sensitivity (Detection rate): 0.3424
Average loss: nan
Average False Alarm: 0.6576
Average F1: 0.49687998839065445
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|96.42|65.75999999999999
|Predicted 1|3.5800000000000005|34.239999999999995

|Acc|Spec|Loss|
0.6533|0.9642000000000001|nan
