inputsize: [[4, 4], [8, 8]]
inlayersize: [16, 32, 64]
latentsize: 2
outlayersize: ListWrapper([64, 32, 16])
outputsize: [[4, 4], [1, 1]]
finalactivation: [None, None, 'sigmoid']
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE 
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9792307692307692
Balanced acc: 0.9475
Average specificity: 0.985
Average sensitivity (Detection rate): 0.9099999999999999
Average loss: [3.97710398]
Average False Alarm: 0.08999999999999998
Average F1: 0.8708133971291866
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|23.64|0.18
|Predicted 1|0.36|1.8200000000000003

|Acc|Spec|Loss|
0.9792307692307692|0.985|[3.97710398]
CV took 90.8411085892002 seconds
Pure training took 86.52129970799989
Test result on unseen data:
Average accuracy: 0.7708000000000002
Balanced acc: 0.7708
Average specificity: 0.9590000000000001
Average sensitivity (Detection rate): 0.5826
Average loss: nan
Average False Alarm: 0.4174
Average F1: 0.7176644493717664
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|95.9|41.74
|Predicted 1|4.1|58.260000000000005

|Acc|Spec|Loss|
0.7708000000000002|0.9590000000000001|nan
