inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 16
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
finalactivation: [None, None, 'sigmoid']
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE 
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9746153846153847
Balanced acc: 0.9770833333333333
Average specificity: 0.9741666666666666
Average sensitivity (Detection rate): 0.9800000000000001
Average loss: [3.89115511]
Average False Alarm: 0.02
Average F1: 0.8558951965065503
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|23.38|0.04
|Predicted 1|0.6199999999999999|1.9600000000000002

|Acc|Spec|Loss|
0.9746153846153847|0.9741666666666666|[3.89115511]
CV took 74.23814863999905 seconds
Pure training took 69.9492366313998
Test result on unseen data:
Average accuracy: 0.7728999999999999
Balanced acc: 0.7729
Average specificity: 0.9526
Average sensitivity (Detection rate): 0.5932000000000001
Average loss: nan
Average False Alarm: 0.4068
Average F1: 0.7231500670486406
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|95.25999999999999|40.67999999999999
|Predicted 1|4.74|59.31999999999999

|Acc|Spec|Loss|
0.7728999999999999|0.9526|nan
