Model type: SVAE
inputsize: [[4, 4], [8, 8]]
inlayersize: [128, 512, 512]
latentsize: 4
outlayersize: ListWrapper([512, 512, 128])
outputsize: [[4, 4], [1, 1]]
fc_size: [64, 32, 1]
Model has 2 inputs, class 0 is where the second input is drawn from a normal distributionwith mean of the first input, class 1 is where it isnt. Proper implementation of SVAE
losses: ['mean_absolute_error', 'mean_absolute_error', 'KLD', 'weighted_ce']
loss_weights: [1, 1, 1, 10]
CEweights: [[1, 10], [1, 1]]
Average accuracy: 0.9815384615384615
Balanced acc: 0.88
Average specificity: 1.0
Average sensitivity (Detection rate): 0.76
Average loss: [3.07990062]
Average False Alarm: 0.24000000000000002
Average F1: 0.8636363636363636
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|12.0|0.24
|Predicted 1|0.0|0.7599999999999999

|Acc|Spec|Loss|
0.9815384615384615|1.0|[3.07990062]
CV took 68.56744162880022 seconds
Pure training took 64.35263362819951
Test result on unseen data:
Average accuracy: 0.6607999999999999
Balanced acc: 0.6607999999999999
Average specificity: 0.9815999999999999
Average sensitivity (Detection rate): 0.3399999999999999
Average loss: nan
Average False Alarm: 0.66
Average F1: 0.5005889281507655
Average cm:
||True 0| True 1|
|-|-|-|
|Predicted 0|98.16|66.0
|Predicted 1|1.8400000000000003|33.99999999999999

|Acc|Spec|Loss|
0.6607999999999999|0.9815999999999999|nan
